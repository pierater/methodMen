
---
title: "Determining text data relation to Hip-Hop artist lyrics"
author: "Benito Sanchez, Sammuel Villavicencio, Martin Almaraz"
date: "May 12, 2017"
output: html_document
---


```{r global_options, include=FALSE}
knitr::opts_chunk$set(prompt=TRUE, comment="", echo=TRUE)
```

In 2013, Robert Galbraith published the novel The Cuckoo's Calling. It was later discovered through linguistic analysis that Robert Galbraith was just a pen name used by JK Rowling, the author of Harry Potter. This analysis flows through a similar vein. We sought to predict the artist of a song based on the form of their lyrics.

## Data Acquisition
The data set of nearly 400,000 songs and lyrics was acquired through MetroLyrics and hosted by kaggle.
```{r}

# read csv
data = read.csv("lyrics.csv", stringsAsFactors = F)
library("caret")
library("stringr")
library(rpart)
library(rpart.plot)

# the data has some features we do not need and others we need to generate
nrow(data)

# it also includes many columns that are unimportant to us
names(data)

```

## Preprocessing and data munging
We decided to focus on the two hip-hop artists with the most lyrics.
```{r}

# remove index, year, genre, and X as they will not help us
# since our data includes many genres of music, we will need to remove anything but Hip-Hop
data = data[data$genre == "Hip-Hop",]

# remove any unessesary columns in the dataframe
data$index = NULL
data$year = NULL
data$genre = NULL
data$X = NULL
data$song = NULL

# remove all but top two artists
top = names(head(sort(table(data$artist), decreasing=TRUE), 2))
artists = data$artist
data = data[is.element(artists, top),]
data = data[!(data$lyrics == ''),]

```


## Create helper functions for sorting and generating features from our data
The features we selected include the number of words per song, the number of commas per song, the number of unique words per song, the number of lines per song and the number of words per line.

We created functions to calculate these features and bind them to the dataframe.
```{r}

# get number of words per lyric
get_num_words_in_lyric = function(lyric) {
    return(sapply(gregexpr("\\W+", lyric), length) + 1)
}

# get number of commas per song
get_num_of_commas = function(lyric) {
    return (str_count(lyric, ','))
}

get_words = function(words)
{
    words = scan(text = words, what='character', quote='')
    words = gsub('[^a-zA-Z]*', '', words)
    words = tolower(words)
    words = words[!(words == '')]
}

# number of unique words used per song
get_num_unique_words = function(lyric) {
    return(length(table(get_words(lyric))))
}

# get number of lines per song
get_num_lines = function(lyric) {
    return(str_count(lyric, '\n') + 1)
}

# get number of words per line per song
get_words_per_line = function(lyric) {
    return(mean(sapply(unlist(strsplit(lyric, '\n', fixed=TRUE)), get_num_words_in_lyric)))
}

# add these new features to our data frame
create_data = function(data) {
    data$words_line = sapply(data[,"lyrics"], get_words_per_line)
    data$num_lines = sapply(data[,"lyrics"], get_num_lines)
    data$num_unique = sapply(data[,"lyrics"], get_num_unique_words)
    data$num_commas = sapply(data[,"lyrics"], get_num_of_commas)
    data$num_words_total = sapply(data[,"lyrics"], get_num_words_in_lyric)
    data$lyrics = NULL
    return(data)
}

data = create_data(data)
```

### Data Exploration

```{r}
  par(mar=c(5.1, max(4.1, max(nchar(names(data)))/1.8), 4.1, 2.1))
  barplot(head(sort(table(data$artist), decreasing = T), 2), horiz = T, las = 1, xlab = "Number of songs per artist", ylab = "Artist", col = c("green4", "red4", "blue4", "orange4"), main = "Number of songs per top 2 artists")

```


### Comparing features sizes for top 2 artists
```{r}
  
  eminem = colMeans(data[data$artist == "eminem", c("num_words_total", "num_unique", "words_line", "num_lines", "num_commas")])
  
par(mar=c(5.1, max(4.1, max(nchar(names(data)))/1.8), 4.1, 2.1))
  barplot(eminem, horiz = T, las = 1, col = c("green4", "red4", "blue4", "orange4", "pink4"), main = "Comparing feature sizes for Eminem")
  
  chrisBrown = colMeans(data[data$artist == "chris-brown", c("num_words_total", "num_unique", "words_line", "num_lines", "num_commas")])
  
  par(mar=c(5.1, max(4.1, max(nchar(names(data)))/1.8), 4.1, 2.1))
  barplot(chrisBrown, horiz = T, las = 1, col =  c("green4", "red4", "blue4", "orange4", "pink4"), main = "Comparing feature sizes for Chris Brown")
```

## Creating our models Knn and classification tree
```{r}
# split into training and test data with a 80/20 split respectively
# split-data function sourced from Dr. Bruns lin-regr-util.R
split_data = function(dat, frac=c(0.75, 0.25)) {
    k = length(frac)
    stopifnot(k > 0)

    n = nrow(dat)
    frac = frac/(sum(frac))
    starts = c(1, round(cumsum(frac) * n)[-k])
    ends = c(starts[-1]-1,n)
    samp = sample(1:n)
    data_sets = list()
    for(i in 1:k) {
        data_sets[[i]] = dat[samp[starts[i]:ends[i]],]
    }
    return(data_sets)
}

data_sets = split_data(data, c(0.80, 0.20))
tr_dat = data_sets[[1]]
test_dat = data_sets[[2]]

# creating models
x = split_data(data)
tr_dat = x[[1]]
te_dat = x[[2]]

tree = rpart(artist ~ ., data = tr_dat, method='class')

knn_model = train(artist ~ ., data = tr_dat, method="knn", tuneLength = 10)

```

## Evaluating the Knn model

Training tests on different number of k values and the k value with the best accuracy is chosen. Here we see that k = 11 gives the best accuracy.
```{r}
plot(knn_model, main = "Accuray vs. Knn value")

d = dist(data)
fit = cmdscale(d)
plot(fit[data$artist == 'chris-brown'], col='orange', xlab='Property 1', ylab='Property 2', main='Songs by Eminem vs Chris Brown')
points(fit[data$artist == 'eminem'], col='green')
legend('topright', legend=c('Chris Brown', 'Eminem'), col=c('orange', 'green'), pch=1)

# do a summary
summary(knn_model)

predicted_knn = predict(knn_model, newdata=te_dat)
table(te_dat$artist, predicted_knn)
mean(te_dat$artist == predicted_knn)
```

## Evaluating the classification tree model
```{r}
prp(tree, extra=106, varlen=-10, main="Decide whether a song is by Eminem or Chris Brown", box.col=c("red4", "lightblue")[tree$frame$yval])

summary(tree)

pred = predict(tree, te_dat, type='class')
table(te_dat$artist, pred)
mean(te_dat$artist == pred)
```
## deciding on what worked best and why
```{r}
# how we will do this?
```
