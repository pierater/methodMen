
---
title: "Determining text data relation to Hip-Hop artist lyrics"
author: "Benito Sanchez, Sammuel Villavicencio, Martin Almaraz"
date: "May 12, 2017"
output: html_document
---


```{r global_options, include=FALSE}
knitr::opts_chunk$set(prompt=TRUE, comment="", echo=TRUE)
```

Given top 100 Hip-Hop artist lyrical data, we plan to create and compare both 
the usage of a Knn classifier and classification tree

## Data Acquisition
```{r}

# read origional csv file
# the file is very large, ~93mb so we will need to do a lot of cleanup
data = read.csv("lyrics.csv", stringsAsFactors = F)
library("caret")
library("stringr")
library(rpart)
library(rpart.plot)

# the data file is extremely large, and full of a lot of data we do not need
nrow(data)

# it also includes many collumns that are unimportant to us
names(data)
# We can remove index, year, genre, and X as they will not help us

```

## Preproccessing and data munging
```{r}

# since our data includes many genres of music, we will need to remove anything but Hip-Hop
data = data[data$genre == "Hip-Hop",]

# we will also need to remove any unessesary collumns in the data.frame
data$index = NULL
data$year = NULL
data$genre = NULL
data$X = NULL
data$song = NULL


# now we will further reduce our data set to only the top 100 artists that we have data for
top = names(head(sort(table(data$artist), decreasing=TRUE), 2))
artists = data$artist

# remove all but top 100 artists
data = data[is.element(artists, top),]
data = data[!(data$lyrics == ''),]

```


## Create helper functions for sorting and generating features from our data
Since we only have lyrics per song and artist, we need to create more features to work with.

Some noteable features we can create are:
    number of words per song
    number of commas per song
    number of unique words per song
    number of lines per song

So we created functions to calculate these features and add them to the current data
```{r}

# get number of words per lyric
get_num_words_in_lyric = function(lyric) {
    return(sapply(gregexpr("\\W+", lyric), length) + 1)
}

# get number of commas per song
get_num_of_commas = function(lyric) {
    return (str_count(lyric, ','))
}


get_words = function(words)
{
    words = scan(text = words, what='character', quote='')
    words = gsub('[^a-zA-Z]*', '', words)
    words = tolower(words)
    words = words[!(words == '')]
}

# number of unique words used per song
get_num_unique_words = function(lyric) {
    return(length(table(get_words(lyric))))
}

# get number of lines per song
get_num_lines = function(lyric) {
    return(str_count(lyric, '\n') + 1)
}

# get number of words per line per song
get_words_per_line = function(lyric) {
    return(mean(sapply(unlist(strsplit(lyric, '\n', fixed=TRUE)), get_num_words_in_lyric)))
}

# add these new features to our data frame
create_data = function(data) {
    data$words_line = sapply(data[,"lyrics"], get_words_per_line)
    data$num_lines = sapply(data[,"lyrics"], get_num_lines)
    data$num_unique = sapply(data[,"lyrics"], get_num_unique_words)
    data$num_commas = sapply(data[,"lyrics"], get_num_of_commas)
    data$num_words_total = sapply(data[,"lyrics"], get_num_words_in_lyric)
    data$lyrics = NULL
    return(data)
}

data = create_data(data)
```

### Data Exploration

```{r}

  barplot(head(sort(table(data$artist), decreasing = T), 4), horiz = T, las = 1, xlab = "Number of songs per artist", ylab = "Artist", col = c("green4", "red4", "blue4", "orange4"), main = "Number of songs per top 4 artists")

```


### Comparing features sizes for top 2 artists
```{r}
  mfrow = c(1,4)
  par(mfrow)
  
  eminem = colMeans(data[data$artist == "eminem", c("num_words_total", "num_unique", "words_line", "num_lines", "num_commas")])
  
  barplot(eminem, horiz = T, las = 1, col = c("green4", "red4", "blue4", "orange4", "pink4"), main = "Comparing feature sizes for Eminem")
  
  chrisBrown = colMeans(data[data$artist == "chris-brown", c("num_words_total", "num_unique", "words_line", "num_lines", "num_commas")])
  
  barplot(chrisBrown, horiz = T, las = 1, col =  c("green4", "red4", "blue4", "orange4", "pink4"), main = "Comparing feature sizes for Chris Brown")
```

## Creating our models Knn and classification tree
```{r}
# split into training and test data with a 80/20 split respectively
# split-data function sourced from Dr. Bruns lin-regr-util.R
split_data = function(dat, frac=c(0.75, 0.25)) {
    k = length(frac)
    stopifnot(k > 0)

    n = nrow(dat)
    frac = frac/(sum(frac))
    starts = c(1, round(cumsum(frac) * n)[-k])
    ends = c(starts[-1]-1,n)
    samp = sample(1:n)
    data_sets = list()
    for(i in 1:k) {
        data_sets[[i]] = dat[samp[starts[i]:ends[i]],]
    }
    return(data_sets)
}

data_sets = split_data(data, c(0.80, 0.20))
tr_dat = data_sets[[1]]
test_dat = data_sets[[2]]

# creating models
x = split_data(data)
tr_dat = x[[1]]
te_dat = x[[2]]

tree = rpart(artist ~ ., data = tr_dat, method='class')

knn_model = train(artist ~ ., data = tr_dat, method="knn", tuneLength = 10)

```

## Evaluating the Knn model

Training tests on different number of k values and the k value with the best accuracy is chosen. Here we see that k = 11 gives the best accuracy.
```{r}
plot(knn_model, main = "Accuray vs. Knn value")

d = dist(data)
fit = cmdscale(d)
plot(fit[data$artist == 'chris-brown'], col='orange', xlab='Property 1', ylab='Property 2')
points(fit[data$artist == 'eminem'], col='green')
legend('topright', legend=c('Chris Brown', 'Eminem'), col=c('orange', 'green'), pch=1, main='Songs by Eminem vs Chris Brown')

# do a summary
summary(knn_model)

predicted_knn = predict(knn_model, newdata=te_dat)
table(te_dat$artist, predicted_knn)
mean(te_dat$artist == predicted_knn)
```

## Evaluating the classification tree model
```{r}
prp(tree, extra=106, varlen=-10, main="Decide whether a song is by Eminem or Chris Brown", box.col=c("red4", "lightblue")[tree$frame$yval])

summary(tree)

pred = predict(tree, te_dat, type='class')
table(te_dat$artist, pred)
mean(te_dat$artist == pred)
```
## deciding on what worked best and why
```{r}
# how we will do this?
```
